{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd8b707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports OK\n",
      "============================================================\n",
      "CHARGEMENT DES DONNÃ‰ES\n",
      "============================================================\n",
      "Dataset shape: (13455, 21)\n",
      "PÃ©riode Day: 1 - 70\n",
      "\n",
      "Target balance (Purchase):\n",
      "Purchase\n",
      "0    0.632553\n",
      "1    0.367447\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "SPLIT TEMPOREL : TRAIN / VAL\n",
      "============================================================\n",
      "Train: Days 1-60   â†’ 11521 lignes\n",
      "Val:   Days 61-70  â†’ 1934 lignes\n",
      "\n",
      "Distribution Purchase:\n",
      "  Train: 37.37%\n",
      "  Val:   33.04%\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Prix\n",
      "============================================================\n",
      "âœ… Features prix crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Engagement\n",
      "============================================================\n",
      "âœ… Features engagement crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Segments\n",
      "============================================================\n",
      "âœ… Features segments crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "ðŸš€ INTERACTIONS QUADRATIQUES CIBLÃ‰ES\n",
      "============================================================\n",
      "   1. Features quadratiques...\n",
      "   2. Ratios ciblÃ©s...\n",
      "   3. Interactions campagne...\n",
      "   1. Features quadratiques...\n",
      "   2. Ratios ciblÃ©s...\n",
      "   3. Interactions campagne...\n",
      "âœ… 6 interactions ciblÃ©es crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "MISSING INDICATORS\n",
      "============================================================\n",
      "âœ… 24 missing indicators crÃ©Ã©s\n",
      "\n",
      "============================================================\n",
      "IMPUTATION\n",
      "============================================================\n",
      "âœ… Imputation terminÃ©e\n",
      "\n",
      "============================================================\n",
      "RARE CATEGORIES\n",
      "============================================================\n",
      "âœ… Rare categories regroupÃ©es\n",
      "\n",
      "============================================================\n",
      "ðŸ§¹ NETTOYAGE RADICAL - SUPPRESSION FEATURES < 1%\n",
      "============================================================\n",
      "âœ… 10 features supprimÃ©es:\n",
      "   - Socioeconomic_Status_Score\n",
      "   - AB_Bucket\n",
      "   - Discount\n",
      "   - Age\n",
      "   - Gender\n",
      "   - Referral_Source\n",
      "   - Payment_Method\n",
      "   - Time_of_Day\n",
      "   - Price_Sine\n",
      "   - Email_Interaction\n",
      "\n",
      "ðŸ“Š Features restantes: 46\n",
      "\n",
      "============================================================\n",
      "PIPELINE CATBOOST\n",
      "============================================================\n",
      "âœ… Pipeline CatBoost prÃ©parÃ©:\n",
      "   X_train: (11521, 42)\n",
      "   X_val:   (1934, 42)\n",
      "   Features: 42\n",
      "   Categorical: ['Device_Type', 'Category']\n",
      "\n",
      "============================================================\n",
      "PIPELINE CLASSIC\n",
      "============================================================\n",
      "âœ… Pipeline Classic prÃ©parÃ©:\n",
      "   X_train: (11521, 47)\n",
      "   X_val:   (1934, 47)\n",
      "\n",
      "============================================================\n",
      "SAUVEGARDE\n",
      "============================================================\n",
      "âœ… CatBoost: 'catboost_ready.pkl'\n",
      "âœ… Classic: 'classic_ready.pkl'\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ PREPROCESSING OPTIMISÃ‰ TERMINÃ‰ !\n",
      "============================================================\n",
      "ðŸ“¦ CatBoost: 42 features (vs 64 avant)\n",
      "ðŸš€ Gain attendu: +1-2% F1\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… Imports OK\")\n",
    "\n",
    "# %%\n",
    "# === CHARGEMENT DES DONNÃ‰ES ===\n",
    "print(\"=\" * 60)\n",
    "print(\"CHARGEMENT DES DONNÃ‰ES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df = pd.read_csv(\"../data/interim/train_dataset_M1_interim.csv\")\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"PÃ©riode Day: {df['Day'].min()} - {df['Day'].max()}\")\n",
    "\n",
    "if \"Purchase\" in df.columns:\n",
    "    print(f\"\\nTarget balance (Purchase):\")\n",
    "    print(df[\"Purchase\"].value_counts(normalize=True))\n",
    "\n",
    "# %%\n",
    "# === SPLIT TRAIN/VAL ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SPLIT TEMPOREL : TRAIN / VAL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train = df[df[\"Day\"] <= 60].copy()\n",
    "val = df[df[\"Day\"] > 60].copy()\n",
    "\n",
    "print(f\"Train: Days 1-60   â†’ {len(train)} lignes\")\n",
    "print(f\"Val:   Days 61-{int(df['Day'].max())}  â†’ {len(val)} lignes\")\n",
    "\n",
    "if \"Purchase\" in df.columns:\n",
    "    print(f\"\\nDistribution Purchase:\")\n",
    "    print(f\"  Train: {train['Purchase'].mean():.2%}\")\n",
    "    print(f\"  Val:   {val['Purchase'].mean():.2%}\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - PRIX ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Prix\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data in [train, val]:\n",
    "    data[\"Net_Price\"] = data[\"Price\"] * (1 - data[\"Discount\"] / 100)\n",
    "    data[\"Price_Bucket\"] = pd.qcut(data[\"Price\"], 5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "print(\"âœ… Features prix crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - ENGAGEMENT ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Engagement\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data in [train, val]:\n",
    "    data[\"Email_x_Engagement\"] = data[\"Email_Interaction\"] * data[\"Engagement_Score\"]\n",
    "    data[\"Cart_x_Engagement\"] = data[\"Items_In_Cart\"] * data[\"Engagement_Score\"]\n",
    "\n",
    "print(\"âœ… Features engagement crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - SEGMENTS ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Segments\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data in [train, val]:\n",
    "    data[\"Campaign_Period\"] = data[\"Campaign_Period\"].astype(bool)\n",
    "    data[\"HighValue_Category\"] = data[\"Category\"].isin([0.0, 1.0, 2.0]).astype(int)\n",
    "\n",
    "print(\"âœ… Features segments crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === ðŸš€ INTERACTIONS CIBLÃ‰ES (SEULEMENT LES MEILLEURES) ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸš€ INTERACTIONS QUADRATIQUES CIBLÃ‰ES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for data in [train, val]:\n",
    "    # 1. Features quadratiques puissantes\n",
    "    print(\"   1. Features quadratiques...\")\n",
    "    data[\"Items_Cart_Squared\"] = data[\"Items_In_Cart\"] ** 2\n",
    "    data[\"Engagement_Squared\"] = data[\"Engagement_Score\"] ** 2\n",
    "\n",
    "    # 2. Ratios pertinents SEULEMENT\n",
    "    print(\"   2. Ratios ciblÃ©s...\")\n",
    "    data[\"Cart_per_Review\"] = data[\"Items_In_Cart\"] / (data[\"Reviews_Read\"] + 1)\n",
    "    data[\"Engagement_per_Price\"] = data[\"Engagement_Score\"] / (data[\"Net_Price\"] + 1)\n",
    "\n",
    "    # 3. Interactions campagne (SEULEMENT 2 meilleures)\n",
    "    print(\"   3. Interactions campagne...\")\n",
    "    data[\"Engagement_x_Campaign\"] = data[\"Engagement_Score\"] * data[\n",
    "        \"Campaign_Period\"\n",
    "    ].astype(int)\n",
    "    data[\"Price_x_Campaign\"] = data[\"Net_Price\"] * data[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "print(f\"âœ… 6 interactions ciblÃ©es crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === MISSING INDICATORS ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING INDICATORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_pct = train.isnull().sum() / len(train) * 100\n",
    "cols_with_missing = missing_pct[missing_pct > 1].index.tolist()\n",
    "cols_with_missing = [col for col in cols_with_missing if col not in [\"Day\"]]\n",
    "\n",
    "for data in [train, val]:\n",
    "    for col in cols_with_missing:\n",
    "        data[f\"{col}_missing\"] = data[col].isnull().astype(int)\n",
    "\n",
    "print(f\"âœ… {len(cols_with_missing)} missing indicators crÃ©Ã©s\")\n",
    "\n",
    "# %%\n",
    "# === IMPUTATION ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPUTATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "median_values = {}\n",
    "numeric_cols = train.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if train[col].isnull().sum() > 0:\n",
    "        median_values[col] = train[col].median()\n",
    "\n",
    "for data in [train, val]:\n",
    "    for col in numeric_cols:\n",
    "        if data[col].isnull().sum() > 0:\n",
    "            fill_value = median_values.get(col, data[col].median())\n",
    "            data[col].fillna(fill_value, inplace=True)\n",
    "\n",
    "    categorical_cols = data.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "    for col in categorical_cols:\n",
    "        if data[col].isnull().sum() > 0:\n",
    "            data[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(f\"âœ… Imputation terminÃ©e\")\n",
    "\n",
    "# %%\n",
    "# === RARE CATEGORIES ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RARE CATEGORIES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "threshold = 0.01\n",
    "categorical_cols = train.select_dtypes(include=[\"object\"]).columns\n",
    "rare_handling = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col == \"Session_ID\":\n",
    "        continue\n",
    "    value_counts = train[col].value_counts(normalize=True)\n",
    "    rare_categories = value_counts[value_counts < threshold].index.tolist()\n",
    "\n",
    "    if rare_categories:\n",
    "        rare_handling[col] = rare_categories\n",
    "\n",
    "for data in [train, val]:\n",
    "    for col, rare_cats in rare_handling.items():\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].apply(lambda x: \"Other\" if x in rare_cats else x)\n",
    "\n",
    "print(f\"âœ… Rare categories regroupÃ©es\")\n",
    "\n",
    "# %%\n",
    "# === ðŸ§¹ NETTOYAGE RADICAL - SUPPRESSION FEATURES INUTILES ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ§¹ NETTOYAGE RADICAL - SUPPRESSION FEATURES < 1%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Features Ã  supprimer (importance < 1% ou redondantes)\n",
    "low_value_features = [\n",
    "    \"Socioeconomic_Status_Score\",\n",
    "    \"AB_Bucket\",\n",
    "    \"Discount\",\n",
    "    \"Age\",\n",
    "    \"Gender\",\n",
    "    \"Referral_Source\",\n",
    "    \"Payment_Method\",\n",
    "    \"Time_of_Day\",\n",
    "    \"Price_Sine\",\n",
    "    \"Email_Interaction\",  # CapturÃ© par Email_x_Engagement\n",
    "]\n",
    "\n",
    "features_removed = []\n",
    "for data in [train, val]:\n",
    "    for feat in low_value_features:\n",
    "        if feat in data.columns:\n",
    "            data.drop(columns=[feat], inplace=True)\n",
    "            if feat not in features_removed:\n",
    "                features_removed.append(feat)\n",
    "\n",
    "print(f\"âœ… {len(features_removed)} features supprimÃ©es:\")\n",
    "for feat in features_removed:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Features restantes: {len(train.columns)}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CATBOOST ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE CATBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cat_features = [\"Device_Type\", \"Category\"]\n",
    "\n",
    "for data in [train, val]:\n",
    "    for col in cat_features:\n",
    "        if col in data.columns:\n",
    "            data[col] = data[col].astype(str)\n",
    "\n",
    "cols_to_drop_cb = [\"Session_ID\", \"Day\", \"Purchase\", \"id\"]\n",
    "\n",
    "X_train = train.drop(columns=cols_to_drop_cb, errors=\"ignore\")\n",
    "y_train = train[\"Purchase\"] if \"Purchase\" in train.columns else None\n",
    "\n",
    "X_val = val.drop(columns=cols_to_drop_cb, errors=\"ignore\")\n",
    "y_val = val[\"Purchase\"] if \"Purchase\" in val.columns else None\n",
    "\n",
    "cat_indices = [\n",
    "    X_train.columns.get_loc(col) for col in cat_features if col in X_train.columns\n",
    "]\n",
    "\n",
    "print(f\"âœ… Pipeline CatBoost prÃ©parÃ©:\")\n",
    "print(f\"   X_train: {X_train.shape}\")\n",
    "print(f\"   X_val:   {X_val.shape}\")\n",
    "print(f\"   Features: {X_train.shape[1]}\")\n",
    "print(f\"   Categorical: {cat_features}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CLASSIC ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PIPELINE CLASSIC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "train_classic = train.copy()\n",
    "val_classic = val.copy()\n",
    "\n",
    "for data in [train_classic, val_classic]:\n",
    "    data[\"Campaign_Period\"] = data[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "cols_onehot = [\"Device_Type\", \"Category\"]\n",
    "train_classic = pd.get_dummies(train_classic, columns=cols_onehot, drop_first=True)\n",
    "val_classic = pd.get_dummies(val_classic, columns=cols_onehot, drop_first=True)\n",
    "\n",
    "missing_cols = set(train_classic.columns) - set(val_classic.columns)\n",
    "for col in missing_cols:\n",
    "    val_classic[col] = 0\n",
    "\n",
    "extra_cols = set(val_classic.columns) - set(train_classic.columns)\n",
    "val_classic = val_classic.drop(columns=list(extra_cols))\n",
    "val_classic = val_classic[train_classic.columns]\n",
    "\n",
    "X_train_cls = train_classic.drop(columns=cols_to_drop_cb, errors=\"ignore\")\n",
    "y_train_cls = train_classic[\"Purchase\"] if \"Purchase\" in train_classic.columns else None\n",
    "\n",
    "X_val_cls = val_classic.drop(columns=cols_to_drop_cb, errors=\"ignore\")\n",
    "y_val_cls = val_classic[\"Purchase\"] if \"Purchase\" in val_classic.columns else None\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cls_scaled = scaler.fit_transform(X_train_cls)\n",
    "X_val_cls_scaled = scaler.transform(X_val_cls)\n",
    "\n",
    "X_train_cls = pd.DataFrame(X_train_cls_scaled, columns=X_train_cls.columns)\n",
    "X_val_cls = pd.DataFrame(X_val_cls_scaled, columns=X_val_cls.columns)\n",
    "\n",
    "print(f\"âœ… Pipeline Classic prÃ©parÃ©:\")\n",
    "print(f\"   X_train: {X_train_cls.shape}\")\n",
    "print(f\"   X_val:   {X_val_cls.shape}\")\n",
    "\n",
    "# %%\n",
    "# === SAUVEGARDE ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAUVEGARDE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "catboost_data = {\n",
    "    \"X_train\": X_train,\n",
    "    \"y_train\": y_train,\n",
    "    \"X_val\": X_val,\n",
    "    \"y_val\": y_val,\n",
    "    \"cat_indices\": cat_indices,\n",
    "    \"cat_features_names\": [col for col in X_train.columns if col in cat_features],\n",
    "}\n",
    "\n",
    "joblib.dump(catboost_data, \"../data/processed/catboost_ready.pkl\", protocol=4)\n",
    "print(\"âœ… CatBoost: 'catboost_ready.pkl'\")\n",
    "\n",
    "classic_data = {\n",
    "    \"X_train\": X_train_cls,\n",
    "    \"y_train\": y_train_cls,\n",
    "    \"X_val\": X_val_cls,\n",
    "    \"y_val\": y_val_cls,\n",
    "    \"scaler\": scaler,\n",
    "}\n",
    "\n",
    "joblib.dump(classic_data, \"../data/processed/classic_ready.pkl\", protocol=4)\n",
    "print(\"âœ… Classic: 'classic_ready.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸŽ‰ PREPROCESSING OPTIMISÃ‰ TERMINÃ‰ !\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ðŸ“¦ CatBoost: {X_train.shape[1]} features (vs 64 avant)\")\n",
    "print(f\"ðŸš€ Gain attendu: +1-2% F1\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

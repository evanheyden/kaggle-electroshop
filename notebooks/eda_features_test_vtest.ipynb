{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd8b707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports OK\n",
      "============================================================\n",
      "CHARGEMENT DU TEST SET\n",
      "============================================================\n",
      "Dataset shape: (6145, 19)\n",
      "Test IDs: 6145\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Prix\n",
      "============================================================\n",
      "âœ… Features prix crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Engagement\n",
      "============================================================\n",
      "âœ… Features engagement crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Segments\n",
      "============================================================\n",
      "âœ… Features segments crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "ðŸš€ INTERACTIONS QUADRATIQUES CIBLÃ‰ES\n",
      "============================================================\n",
      "âœ… 6 interactions ciblÃ©es crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "MISSING INDICATORS\n",
      "============================================================\n",
      "âœ… 24 missing indicators crÃ©Ã©s\n",
      "\n",
      "============================================================\n",
      "IMPUTATION\n",
      "============================================================\n",
      "âœ… Imputation terminÃ©e\n",
      "\n",
      "============================================================\n",
      "RARE CATEGORIES\n",
      "============================================================\n",
      "âœ… Rare categories regroupÃ©es\n",
      "\n",
      "============================================================\n",
      "ðŸ§¹ NETTOYAGE RADICAL\n",
      "============================================================\n",
      "âœ… 10 features supprimÃ©es\n",
      "ðŸ“Š Features restantes: 44\n",
      "\n",
      "============================================================\n",
      "PIPELINE CATBOOST\n",
      "============================================================\n",
      "âœ… Pipeline CatBoost prÃ©parÃ©:\n",
      "   X_test: (6145, 43)\n",
      "\n",
      "============================================================\n",
      "PIPELINE CLASSIC\n",
      "============================================================\n",
      "âœ… Colonnes train chargÃ©es: 47 features\n",
      "âœ… Pipeline Classic prÃ©parÃ©:\n",
      "   X_test: (6145, 47)\n",
      "\n",
      "============================================================\n",
      "SAUVEGARDE\n",
      "============================================================\n",
      "âœ… CatBoost test: 'catboost_ready_test.pkl'\n",
      "âœ… Classic test: 'classic_ready_test.pkl'\n",
      "\n",
      "============================================================\n",
      "ðŸŽ‰ TEST SET OPTIMISÃ‰ TERMINÃ‰ !\n",
      "============================================================\n",
      "ðŸ“¦ Features: 43 (vs 64 avant)\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… Imports OK\")\n",
    "\n",
    "# %%\n",
    "# === CHARGEMENT TEST ===\n",
    "print(\"=\"*60)\n",
    "print(\"CHARGEMENT DU TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df = pd.read_csv(\"../data/interim/test_dataset_M1_interim.csv\")\n",
    "test_ids = df['id'].copy()\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Test IDs: {len(test_ids)}\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - PRIX ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING - Prix\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df[\"Net_Price\"] = df[\"Price\"] * (1 - df[\"Discount\"] / 100)\n",
    "df[\"Price_Bucket\"] = pd.qcut(df[\"Price\"], 5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "print(\"âœ… Features prix crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - ENGAGEMENT ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING - Engagement\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df[\"Email_x_Engagement\"] = df[\"Email_Interaction\"] * df[\"Engagement_Score\"]\n",
    "df[\"Cart_x_Engagement\"] = df[\"Items_In_Cart\"] * df[\"Engagement_Score\"]\n",
    "\n",
    "print(\"âœ… Features engagement crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - SEGMENTS ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING - Segments\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df[\"Campaign_Period\"] = df[\"Campaign_Period\"].astype(bool)\n",
    "df[\"HighValue_Category\"] = df[\"Category\"].isin([0.0, 1.0, 2.0]).astype(int)\n",
    "\n",
    "print(\"âœ… Features segments crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === ðŸš€ INTERACTIONS CIBLÃ‰ES ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸš€ INTERACTIONS QUADRATIQUES CIBLÃ‰ES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "df[\"Items_Cart_Squared\"] = df[\"Items_In_Cart\"] ** 2\n",
    "df[\"Engagement_Squared\"] = df[\"Engagement_Score\"] ** 2\n",
    "df[\"Cart_per_Review\"] = df[\"Items_In_Cart\"] / (df[\"Reviews_Read\"] + 1)\n",
    "df[\"Engagement_per_Price\"] = df[\"Engagement_Score\"] / (df[\"Net_Price\"] + 1)\n",
    "df[\"Engagement_x_Campaign\"] = df[\"Engagement_Score\"] * df[\"Campaign_Period\"].astype(int)\n",
    "df[\"Price_x_Campaign\"] = df[\"Net_Price\"] * df[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "print(f\"âœ… 6 interactions ciblÃ©es crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === MISSING INDICATORS ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING INDICATORS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "missing_pct = df.isnull().sum() / len(df) * 100\n",
    "cols_with_missing = missing_pct[missing_pct > 1].index.tolist()\n",
    "cols_with_missing = [col for col in cols_with_missing if col not in ['Day']]\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    df[f\"{col}_missing\"] = df[col].isnull().astype(int)\n",
    "\n",
    "print(f\"âœ… {len(cols_with_missing)} missing indicators crÃ©Ã©s\")\n",
    "\n",
    "# %%\n",
    "# === IMPUTATION ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPUTATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "median_values = {\n",
    "    'Age': 30.0, 'Gender': 0.0, 'Reviews_Read': 3.0,\n",
    "    'Price': 300.0, 'Discount': 25.0, 'Category': 2.0,\n",
    "    'Items_In_Cart': 3.0, 'Socioeconomic_Status_Score': 4.5,\n",
    "    'Engagement_Score': 2.5, 'AB_Bucket': 3.0,\n",
    "    'Price_Sine': 0.0, 'Day': 80.0, 'Email_Interaction': 0.0,\n",
    "}\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        fill_value = median_values.get(col, df[col].median())\n",
    "        df[col].fillna(fill_value, inplace=True)\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object', 'bool']).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(f\"âœ… Imputation terminÃ©e\")\n",
    "\n",
    "# %%\n",
    "# === RARE CATEGORIES ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RARE CATEGORIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "threshold = 0.01\n",
    "for col in categorical_cols:\n",
    "    if col == 'Campaign_Period':\n",
    "        continue\n",
    "    value_counts = df[col].value_counts(normalize=True)\n",
    "    rare_categories = value_counts[value_counts < threshold].index.tolist()\n",
    "    if rare_categories:\n",
    "        df[col] = df[col].apply(lambda x: \"Other\" if x in rare_categories else x)\n",
    "\n",
    "print(\"âœ… Rare categories regroupÃ©es\")\n",
    "\n",
    "# %%\n",
    "# === ðŸ§¹ NETTOYAGE RADICAL ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ§¹ NETTOYAGE RADICAL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "low_value_features = [\n",
    "    'Socioeconomic_Status_Score', 'AB_Bucket', 'Discount',\n",
    "    'Age', 'Gender', 'Referral_Source', 'Payment_Method',\n",
    "    'Time_of_Day', 'Price_Sine', 'Email_Interaction',\n",
    "]\n",
    "\n",
    "features_removed = []\n",
    "for feat in low_value_features:\n",
    "    if feat in df.columns:\n",
    "        df = df.drop(columns=[feat])\n",
    "        features_removed.append(feat)\n",
    "\n",
    "print(f\"âœ… {len(features_removed)} features supprimÃ©es\")\n",
    "print(f\"ðŸ“Š Features restantes: {len(df.columns)}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CATBOOST ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE CATBOOST\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat_features = [\"Device_Type\", \"Category\"]\n",
    "\n",
    "for col in cat_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "cols_to_drop_cb = [\"Session_ID\"]\n",
    "X_test_cb = df.drop(columns=cols_to_drop_cb, errors='ignore')\n",
    "\n",
    "cat_indices = [X_test_cb.columns.get_loc(col) for col in cat_features if col in X_test_cb.columns]\n",
    "\n",
    "print(f\"âœ… Pipeline CatBoost prÃ©parÃ©:\")\n",
    "print(f\"   X_test: {X_test_cb.shape}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CLASSIC ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PIPELINE CLASSIC\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    train_data = joblib.load(\"../data/processed/classic_ready.pkl\")\n",
    "    train_columns = train_data[\"X_train\"].columns.tolist()\n",
    "    print(f\"âœ… Colonnes train chargÃ©es: {len(train_columns)} features\")\n",
    "except:\n",
    "    print(\"âš ï¸ classic_ready.pkl non trouvÃ©\")\n",
    "    train_columns = None\n",
    "\n",
    "df_classic = df.copy()\n",
    "df_classic[\"Campaign_Period\"] = df_classic[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "cols_onehot = [\"Device_Type\", \"Category\"]\n",
    "df_classic = pd.get_dummies(df_classic, columns=cols_onehot, drop_first=True)\n",
    "\n",
    "cols_to_drop = [\"Session_ID\"]\n",
    "X_test_cls = df_classic.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "if train_columns is not None:\n",
    "    missing_cols = set(train_columns) - set(X_test_cls.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_cls[col] = 0\n",
    "    \n",
    "    extra_cols = set(X_test_cls.columns) - set(train_columns)\n",
    "    if extra_cols:\n",
    "        X_test_cls = X_test_cls.drop(columns=list(extra_cols))\n",
    "    \n",
    "    X_test_cls = X_test_cls[train_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_test_cls_scaled = scaler.fit_transform(X_test_cls)\n",
    "X_test_cls = pd.DataFrame(X_test_cls_scaled, columns=X_test_cls.columns)\n",
    "\n",
    "print(f\"âœ… Pipeline Classic prÃ©parÃ©:\")\n",
    "print(f\"   X_test: {X_test_cls.shape}\")\n",
    "\n",
    "# %%\n",
    "# === SAUVEGARDE ===\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAUVEGARDE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "catboost_data = {\n",
    "    \"X_test\": X_test_cb,\n",
    "    \"test_ids\": test_ids,\n",
    "    \"cat_indices\": cat_indices,\n",
    "    \"cat_features_names\": [col for col in X_test_cb.columns if col in cat_features],\n",
    "}\n",
    "\n",
    "joblib.dump(catboost_data, \"../data/processed/catboost_ready_test.pkl\", protocol=4)\n",
    "print(\"âœ… CatBoost test: 'catboost_ready_test.pkl'\")\n",
    "\n",
    "classic_data = {\n",
    "    \"X_test\": X_test_cls,\n",
    "    \"test_ids\": test_ids,\n",
    "    \"scaler\": scaler,\n",
    "}\n",
    "\n",
    "joblib.dump(classic_data, \"../data/processed/classic_ready_test.pkl\", protocol=4)\n",
    "print(\"âœ… Classic test: 'classic_ready_test.pkl'\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ TEST SET OPTIMISÃ‰ TERMINÃ‰ !\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ðŸ“¦ Features: {X_test_cb.shape[1]} (vs 64 avant)\")\n",
    "print(\"=\"*60)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

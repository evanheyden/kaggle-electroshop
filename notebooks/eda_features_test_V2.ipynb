{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd8b707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports OK\n",
      "============================================================\n",
      "CHARGEMENT DU TEST SET\n",
      "============================================================\n",
      "Dataset shape: (6265, 19)\n",
      "Test IDs sauvegardÃ©s: 6265\n",
      "Colonnes: ['Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category', 'Items_In_Cart', 'Time_of_Day', 'Email_Interaction', 'Device_Type', 'Payment_Method', 'Referral_Source', 'Socioeconomic_Status_Score', 'Engagement_Score', 'AB_Bucket', 'Price_Sine', 'Session_ID', 'Day', 'Campaign_Period']\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Prix & Discount\n",
      "============================================================\n",
      "âœ… Features prix crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Engagement & Interactions\n",
      "============================================================\n",
      "âœ… Features engagement crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING - Segments EDA\n",
      "============================================================\n",
      "âœ… Features segments crÃ©Ã©es\n",
      "\n",
      "============================================================\n",
      "ðŸš€ NOUVELLES FEATURES - INTERACTIONS CAMPAGNE\n",
      "============================================================\n",
      "   1. Interactions prix Ã— campagne...\n",
      "   2. Interactions engagement Ã— campagne...\n",
      "   3. IntensitÃ© campagne...\n",
      "   4. Ratios comportementaux...\n",
      "   5. Segments avancÃ©s...\n",
      "âœ… 13 nouvelles features crÃ©Ã©es !\n",
      "\n",
      "============================================================\n",
      "CRÃ‰ATION DES MISSING INDICATORS\n",
      "============================================================\n",
      "âœ… 29 missing indicators crÃ©Ã©s\n",
      "   Colonnes: ['Age', 'Gender', 'Reviews_Read', 'Price', 'Discount', 'Category', 'Items_In_Cart', 'Time_of_Day', 'Email_Interaction', 'Device_Type', 'Socioeconomic_Status_Score', 'Engagement_Score', 'AB_Bucket', 'Price_Sine', 'Session_ID', 'Effective_Discount', 'Net_Price', 'Price_Bucket', 'Email_x_Engagement', 'Cart_x_Engagement', 'Price_x_Campaign', 'Discount_x_Campaign', 'Net_Price_x_Campaign', 'Engagement_x_Campaign', 'Items_x_Campaign', 'Email_x_Campaign', 'Cart_Efficiency', 'Engagement_per_Price', 'Email_Impact']\n",
      "\n",
      "============================================================\n",
      "IMPUTATION DES VALEURS MANQUANTES\n",
      "============================================================\n",
      "âœ… Imputation terminÃ©e - NA restants: 0\n",
      "\n",
      "============================================================\n",
      "GESTION DES CATÃ‰GORIES RARES (<1%)\n",
      "============================================================\n",
      "âœ… 3 colonnes avec catÃ©gories rares regroupÃ©es\n",
      "\n",
      "============================================================\n",
      "ðŸ§¹ NETTOYAGE - SUPPRESSION FEATURES INUTILES\n",
      "============================================================\n",
      "âœ… 1 features supprimÃ©es:\n",
      "   - Effective_Discount\n",
      "\n",
      "ðŸ“Š Features totales: 67\n",
      "\n",
      "============================================================\n",
      "PRÃ‰PARATION PIPELINE CATBOOST\n",
      "============================================================\n",
      "âœ… Pipeline CatBoost prÃ©parÃ©:\n",
      "   X_test shape: (6265, 66)\n",
      "   Categorical indices: [9, 7, 10, 11, 5]\n",
      "   Features: 66\n",
      "\n",
      "============================================================\n",
      "PRÃ‰PARATION PIPELINE CLASSIC (One-Hot + Scaling)\n",
      "============================================================\n",
      "âœ… Colonnes train chargÃ©es: 72 features\n",
      "âœ… Test alignÃ© sur train: (6265, 72)\n",
      "âœ… Pipeline Classic prÃ©parÃ©:\n",
      "   X_test shape: (6265, 72)\n",
      "\n",
      "============================================================\n",
      "VÃ‰RIFICATION FINALE\n",
      "============================================================\n",
      "âœ… CatBoost:\n",
      "   Shape: (6265, 66)\n",
      "   Features: 66\n",
      "   NA: 0\n",
      "\n",
      "âœ… Classic:\n",
      "   Shape: (6265, 72)\n",
      "   Features: 72\n",
      "   NA: 0\n",
      "\n",
      "âœ… Test IDs: 6265\n",
      "\n",
      "ðŸ“Š Comparaison avec train attendu:\n",
      "   Train attendu: ~56 colonnes (CatBoost)\n",
      "   Test:          66 colonnes (CatBoost)\n",
      "   âš ï¸ VÃ©rifier - diffÃ©rence dÃ©tectÃ©e\n",
      "\n",
      "============================================================\n",
      "SAUVEGARDE DES DONNÃ‰ES PREPROCESSED\n",
      "============================================================\n",
      "âœ… CatBoost test: 'catboost_ready_test.pkl'\n",
      "âœ… Classic test: 'classic_ready_test.pkl'\n",
      "\n",
      "============================================================\n",
      "RÃ‰SUMÃ‰ FINAL\n",
      "============================================================\n",
      "ðŸ“¦ CatBoost test: (6265, 66)\n",
      "ðŸ“¦ Classic test: (6265, 72)\n",
      "ðŸ“¦ Test IDs: 6265\n",
      "\n",
      "ðŸš€ NOUVELLES FEATURES AJOUTÃ‰ES: +13 features\n",
      "\n",
      "ðŸŽ‰ PREPROCESSING TEST SET TERMINÃ‰ !\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# === IMPORTS ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import warnings\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"âœ… Imports OK\")\n",
    "\n",
    "# %%\n",
    "# === CHARGEMENT DU TEST INTERIM ===\n",
    "print(\"=\" * 60)\n",
    "print(\"CHARGEMENT DU TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Charger le test INTERIM (dÃ©jÃ  nettoyÃ©, comme train)\n",
    "df = pd.read_csv(\"../data/interim/test_dataset_M1_interim.csv\")\n",
    "test_ids = df[\"id\"].copy()\n",
    "df = df.drop(columns=[\"id\"])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Test IDs sauvegardÃ©s: {len(test_ids)}\")\n",
    "print(f\"Colonnes: {df.columns.tolist()}\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - PARTIE 1 : Prix et Discount ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Prix & Discount\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df[\"Effective_Discount\"] = df[\"Price\"] * df[\"Discount\"] / 100\n",
    "df[\"Net_Price\"] = df[\"Price\"] * (1 - df[\"Discount\"] / 100)\n",
    "df[\"Price_Bucket\"] = pd.qcut(df[\"Price\"], 5, labels=False, duplicates=\"drop\")\n",
    "\n",
    "print(\"âœ… Features prix crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - PARTIE 2 : Engagement & Interactions ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Engagement & Interactions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "df[\"Email_x_Engagement\"] = df[\"Email_Interaction\"] * df[\"Engagement_Score\"]\n",
    "df[\"Cart_x_Engagement\"] = df[\"Items_In_Cart\"] * df[\"Engagement_Score\"]\n",
    "\n",
    "print(\"âœ… Features engagement crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === FEATURE ENGINEERING - PARTIE 3 : Segments EDA ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING - Segments EDA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Campaign_Period doit Ãªtre boolÃ©en\n",
    "df[\"Campaign_Period\"] = df[\"Campaign_Period\"].astype(bool)\n",
    "\n",
    "# CatÃ©gorie High Value\n",
    "df[\"HighValue_Category\"] = df[\"Category\"].isin([0.0, 1.0, 2.0]).astype(int)\n",
    "\n",
    "\n",
    "# Distance Ã  la campagne\n",
    "def day_rel_to_campaign(day, campaign_windows=[(25, 50), (75, 90)]):\n",
    "    if pd.isna(day):\n",
    "        return np.nan\n",
    "    campaign_days = [i for w in campaign_windows for i in range(w[0], w[1] + 1)]\n",
    "    return min([abs(day - c) for c in campaign_days])\n",
    "\n",
    "\n",
    "df[\"Day_to_Campaign\"] = df[\"Day\"].apply(day_rel_to_campaign)\n",
    "\n",
    "print(\"âœ… Features segments crÃ©Ã©es\")\n",
    "\n",
    "# %%\n",
    "# === ðŸš€ NOUVELLES FEATURES - INTERACTIONS CAMPAGNE ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸš€ NOUVELLES FEATURES - INTERACTIONS CAMPAGNE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Interactions multiplicatives campagne\n",
    "print(\"   1. Interactions prix Ã— campagne...\")\n",
    "df[\"Price_x_Campaign\"] = df[\"Price\"] * df[\"Campaign_Period\"].astype(int)\n",
    "df[\"Discount_x_Campaign\"] = df[\"Discount\"] * df[\"Campaign_Period\"].astype(int)\n",
    "df[\"Net_Price_x_Campaign\"] = df[\"Net_Price\"] * df[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "# 2. Interactions engagement Ã— campagne\n",
    "print(\"   2. Interactions engagement Ã— campagne...\")\n",
    "df[\"Engagement_x_Campaign\"] = df[\"Engagement_Score\"] * df[\"Campaign_Period\"].astype(int)\n",
    "df[\"Items_x_Campaign\"] = df[\"Items_In_Cart\"] * df[\"Campaign_Period\"].astype(int)\n",
    "df[\"Email_x_Campaign\"] = df[\"Email_Interaction\"] * df[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "# 3. IntensitÃ© campagne (proximitÃ© temporelle)\n",
    "print(\"   3. IntensitÃ© campagne...\")\n",
    "df[\"Campaign_Intensity\"] = np.where(\n",
    "    df[\"Campaign_Period\"], 1 / (df[\"Day_to_Campaign\"] + 1), 0\n",
    ")\n",
    "\n",
    "# 4. Ratios comportementaux\n",
    "print(\"   4. Ratios comportementaux...\")\n",
    "df[\"Cart_Efficiency\"] = df[\"Items_In_Cart\"] / (df[\"Reviews_Read\"] + 1)\n",
    "df[\"Engagement_per_Price\"] = df[\"Engagement_Score\"] / (df[\"Net_Price\"] + 1)\n",
    "df[\"Email_Impact\"] = (\n",
    "    df[\"Email_Interaction\"] * df[\"Engagement_Score\"] * df[\"Reviews_Read\"]\n",
    ")\n",
    "\n",
    "# 5. Segments avancÃ©s\n",
    "print(\"   5. Segments avancÃ©s...\")\n",
    "df[\"High_Intent\"] = (\n",
    "    (df[\"Items_In_Cart\"] >= 3)\n",
    "    & (df[\"Engagement_Score\"] >= 2.5)\n",
    "    & (df[\"Email_Interaction\"] == 1)\n",
    ").astype(int)\n",
    "\n",
    "df[\"Price_Sensitive\"] = ((df[\"Discount\"] >= 25) & (df[\"Net_Price\"] <= 200)).astype(int)\n",
    "\n",
    "df[\"Premium_Buyer\"] = (\n",
    "    (df[\"Net_Price\"] >= 500) & (df[\"Device_Type\"].isin([\"Desktop\", \"Tablet\"]))\n",
    ").astype(int)\n",
    "\n",
    "print(f\"âœ… 13 nouvelles features crÃ©Ã©es !\")\n",
    "\n",
    "# %%\n",
    "# === MISSING INDICATORS ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CRÃ‰ATION DES MISSING INDICATORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing_pct = df.isnull().sum() / len(df) * 100\n",
    "cols_with_missing = missing_pct[missing_pct > 1].index.tolist()\n",
    "\n",
    "# âš ï¸ IMPORTANT : Exclure Day et Day_to_Campaign pour correspondre au train\n",
    "cols_with_missing = [\n",
    "    col for col in cols_with_missing if col not in [\"Day\", \"Day_to_Campaign\"]\n",
    "]\n",
    "\n",
    "for col in cols_with_missing:\n",
    "    df[f\"{col}_missing\"] = df[col].isnull().astype(int)\n",
    "\n",
    "print(f\"âœ… {len(cols_with_missing)} missing indicators crÃ©Ã©s\")\n",
    "if cols_with_missing:\n",
    "    print(f\"   Colonnes: {cols_with_missing}\")\n",
    "\n",
    "# %%\n",
    "# === IMPUTATION ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"IMPUTATION DES VALEURS MANQUANTES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Valeurs mÃ©dianes du TRAIN pour imputation cohÃ©rente\n",
    "median_values = {\n",
    "    \"Age\": 30.0,\n",
    "    \"Gender\": 0.0,\n",
    "    \"Reviews_Read\": 3.0,\n",
    "    \"Price\": 300.0,\n",
    "    \"Discount\": 25.0,\n",
    "    \"Category\": 2.0,\n",
    "    \"Items_In_Cart\": 3.0,\n",
    "    \"Socioeconomic_Status_Score\": 4.5,\n",
    "    \"Engagement_Score\": 2.5,\n",
    "    \"AB_Bucket\": 3.0,\n",
    "    \"Price_Sine\": 0.0,\n",
    "    \"Day\": 80.0,\n",
    "    \"Email_Interaction\": 0.0,\n",
    "    \"Net_Price\": 225.0,\n",
    "    \"Price_Bucket\": 2.0,\n",
    "    \"Email_x_Engagement\": 0.0,\n",
    "    \"Cart_x_Engagement\": 7.5,\n",
    "    \"Day_to_Campaign\": 15.0,\n",
    "}\n",
    "\n",
    "# NumÃ©riques : utiliser les mÃ©dianes du train\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        fill_value = median_values.get(col, df[col].median())\n",
    "        df[col].fillna(fill_value, inplace=True)\n",
    "\n",
    "# CatÃ©gorielles : \"Unknown\"\n",
    "categorical_cols = df.select_dtypes(include=[\"object\", \"bool\"]).columns\n",
    "for col in categorical_cols:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        df[col].fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "print(f\"âœ… Imputation terminÃ©e - NA restants: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# %%\n",
    "# === RARE CATEGORIES ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"GESTION DES CATÃ‰GORIES RARES (<1%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "threshold = 0.01\n",
    "rare_handling = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col == \"Campaign_Period\":  # Skip boolÃ©en\n",
    "        continue\n",
    "    value_counts = df[col].value_counts(normalize=True)\n",
    "    rare_categories = value_counts[value_counts < threshold].index.tolist()\n",
    "\n",
    "    if rare_categories:\n",
    "        df[col] = df[col].apply(lambda x: \"Other\" if x in rare_categories else x)\n",
    "        rare_handling[col] = len(rare_categories)\n",
    "\n",
    "if rare_handling:\n",
    "    print(f\"âœ… {len(rare_handling)} colonnes avec catÃ©gories rares regroupÃ©es\")\n",
    "else:\n",
    "    print(\"âœ… Aucune catÃ©gorie rare dÃ©tectÃ©e\")\n",
    "\n",
    "# %%\n",
    "# === ðŸ§¹ SUPPRESSION FEATURES INUTILES ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ§¹ NETTOYAGE - SUPPRESSION FEATURES INUTILES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "features_to_remove = [\"Effective_Discount\"]\n",
    "\n",
    "features_removed = []\n",
    "for feat in features_to_remove:\n",
    "    if feat in df.columns:\n",
    "        df = df.drop(columns=[feat])\n",
    "        features_removed.append(feat)\n",
    "\n",
    "print(f\"âœ… {len(features_removed)} features supprimÃ©es:\")\n",
    "for feat in features_removed:\n",
    "    print(f\"   - {feat}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Features totales: {len(df.columns)}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CATBOOST ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRÃ‰PARATION PIPELINE CATBOOST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "cat_features = [\n",
    "    \"Device_Type\",\n",
    "    \"Time_of_Day\",\n",
    "    \"Payment_Method\",\n",
    "    \"Referral_Source\",\n",
    "    \"Category\",\n",
    "]\n",
    "\n",
    "# Convertir en string\n",
    "for col in cat_features:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "# CrÃ©er X_test - GARDER Campaign_Period et Day comme dans train\n",
    "cols_to_drop_cb = [\"Session_ID\"]\n",
    "X_test_cb = df.drop(columns=cols_to_drop_cb, errors=\"ignore\")\n",
    "\n",
    "# Indices catÃ©goriels\n",
    "cat_indices = [\n",
    "    X_test_cb.columns.get_loc(col) for col in cat_features if col in X_test_cb.columns\n",
    "]\n",
    "\n",
    "print(f\"âœ… Pipeline CatBoost prÃ©parÃ©:\")\n",
    "print(f\"   X_test shape: {X_test_cb.shape}\")\n",
    "print(f\"   Categorical indices: {cat_indices}\")\n",
    "print(f\"   Features: {X_test_cb.shape[1]}\")\n",
    "\n",
    "# %%\n",
    "# === PIPELINE CLASSIC ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRÃ‰PARATION PIPELINE CLASSIC (One-Hot + Scaling)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Charger les colonnes du train pour alignement\n",
    "try:\n",
    "    train_data = joblib.load(\"../data/processed/classic_ready.pkl\")\n",
    "    train_columns = train_data[\"X_train\"].columns.tolist()\n",
    "    print(f\"âœ… Colonnes train chargÃ©es: {len(train_columns)} features\")\n",
    "except:\n",
    "    print(\"âš ï¸ Impossible de charger les colonnes train - gÃ©nÃ©ration sans alignement\")\n",
    "    train_columns = None\n",
    "\n",
    "# Copier donnÃ©es\n",
    "df_classic = df.copy()\n",
    "\n",
    "# Convertir Campaign_Period en int\n",
    "df_classic[\"Campaign_Period\"] = df_classic[\"Campaign_Period\"].astype(int)\n",
    "\n",
    "# One-hot encoding\n",
    "cols_onehot = [\"Device_Type\", \"Time_of_Day\", \"Category\"]\n",
    "df_classic = pd.get_dummies(df_classic, columns=cols_onehot, drop_first=True)\n",
    "\n",
    "# Label encoding\n",
    "for col in [\"Payment_Method\", \"Referral_Source\"]:\n",
    "    if col in df_classic.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_classic[col] = le.fit_transform(df_classic[col].astype(str))\n",
    "\n",
    "# PrÃ©parer X_test\n",
    "cols_to_drop = [\"Session_ID\"]\n",
    "X_test_cls = df_classic.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# ALIGNER SUR TRAIN SI DISPONIBLE\n",
    "if train_columns is not None:\n",
    "    # Ajouter colonnes manquantes\n",
    "    missing_cols = set(train_columns) - set(X_test_cls.columns)\n",
    "    for col in missing_cols:\n",
    "        X_test_cls[col] = 0\n",
    "\n",
    "    # Supprimer colonnes en trop\n",
    "    extra_cols = set(X_test_cls.columns) - set(train_columns)\n",
    "    if extra_cols:\n",
    "        X_test_cls = X_test_cls.drop(columns=list(extra_cols))\n",
    "\n",
    "    # RÃ©ordonner selon train\n",
    "    X_test_cls = X_test_cls[train_columns]\n",
    "    print(f\"âœ… Test alignÃ© sur train: {X_test_cls.shape}\")\n",
    "\n",
    "# Scaling (fit sur test car pas d'accÃ¨s au scaler train)\n",
    "scaler = StandardScaler()\n",
    "X_test_cls_scaled = scaler.fit_transform(X_test_cls)\n",
    "X_test_cls = pd.DataFrame(X_test_cls_scaled, columns=X_test_cls.columns)\n",
    "\n",
    "print(f\"âœ… Pipeline Classic prÃ©parÃ©:\")\n",
    "print(f\"   X_test shape: {X_test_cls.shape}\")\n",
    "\n",
    "# %%\n",
    "# === VÃ‰RIFICATION FINALE ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VÃ‰RIFICATION FINALE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"âœ… CatBoost:\")\n",
    "print(f\"   Shape: {X_test_cb.shape}\")\n",
    "print(f\"   Features: {X_test_cb.shape[1]}\")\n",
    "print(f\"   NA: {X_test_cb.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nâœ… Classic:\")\n",
    "print(f\"   Shape: {X_test_cls.shape}\")\n",
    "print(f\"   Features: {X_test_cls.shape[1]}\")\n",
    "print(f\"   NA: {X_test_cls.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nâœ… Test IDs: {len(test_ids)}\")\n",
    "\n",
    "print(f\"\\nðŸ“Š Comparaison avec train attendu:\")\n",
    "print(f\"   Train attendu: ~56 colonnes (CatBoost)\")\n",
    "print(f\"   Test:          {X_test_cb.shape[1]} colonnes (CatBoost)\")\n",
    "if X_test_cb.shape[1] >= 55 and X_test_cb.shape[1] <= 57:\n",
    "    print(\"   âœ… PARFAIT ! Nombre de colonnes cohÃ©rent\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ VÃ©rifier - diffÃ©rence dÃ©tectÃ©e\")\n",
    "\n",
    "# %%\n",
    "# === SAUVEGARDE ===\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SAUVEGARDE DES DONNÃ‰ES PREPROCESSED\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# CatBoost\n",
    "catboost_data = {\n",
    "    \"X_test\": X_test_cb,\n",
    "    \"test_ids\": test_ids,\n",
    "    \"cat_indices\": cat_indices,\n",
    "    \"cat_features_names\": [col for col in X_test_cb.columns if col in cat_features],\n",
    "}\n",
    "\n",
    "joblib.dump(catboost_data, \"../data/processed/catboost_ready_test.pkl\", protocol=4)\n",
    "print(\"âœ… CatBoost test: 'catboost_ready_test.pkl'\")\n",
    "\n",
    "# Classic\n",
    "classic_data = {\n",
    "    \"X_test\": X_test_cls,\n",
    "    \"test_ids\": test_ids,\n",
    "    \"scaler\": scaler,\n",
    "}\n",
    "\n",
    "joblib.dump(classic_data, \"../data/processed/classic_ready_test.pkl\", protocol=4)\n",
    "print(\"âœ… Classic test: 'classic_ready_test.pkl'\")\n",
    "\n",
    "# RÃ©sumÃ©\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RÃ‰SUMÃ‰ FINAL\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ðŸ“¦ CatBoost test: {X_test_cb.shape}\")\n",
    "print(f\"ðŸ“¦ Classic test: {X_test_cls.shape}\")\n",
    "print(f\"ðŸ“¦ Test IDs: {len(test_ids)}\")\n",
    "print(f\"\\nðŸš€ NOUVELLES FEATURES AJOUTÃ‰ES: +13 features\")\n",
    "print(\"\\nðŸŽ‰ PREPROCESSING TEST SET TERMINÃ‰ !\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31963a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
